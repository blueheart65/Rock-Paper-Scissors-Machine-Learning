{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of RockPaperScissors.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "19-yotreqCnnmZHdDp18cxqeOke2Z92m3",
      "authorship_tag": "ABX9TyMjB+t13Y+Fa8/0ddZdsFYZ"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnBfG88g-lDK"
      },
      "source": [
        "Nama : Fernando\n",
        "Email : fernandosianturi58@gmail.com\n",
        "Address : Jl.Pahlawan 12 Kel.Bukit Merapin, Kec.Gerunggang, Kota Pangkalpinang, Bangka Belitung."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nUtYwXG7UPj"
      },
      "source": [
        "pip install split-folders"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cAPQrzrXT4d"
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "  https://dicodingacademy.blob.core.windows.net/picodiploma/ml_pemula_academy/rockpaperscissors.zip \\\n",
        "  -O /tmp/rockpaperscissors.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMfIF3dLw5-7"
      },
      "source": [
        "!unzip /tmp/rockpaperscissors.zip -d /tmp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBkz1mHp9NfT"
      },
      "source": [
        "import os\n",
        "import splitfolders\n",
        "base_directory = '/tmp/rockpaperscissors/rps-cv-images'\n",
        "os.remove('/tmp/rockpaperscissors/rps-cv-images/README_rpc-cv-images.txt')\n",
        "splitfolders.ratio(base_directory, output = base_directory, seed = 42, ratio=(.6, .4))\n",
        "\n",
        "train_directory = os.path.join(base_directory,'train')\n",
        "val_directory = os.path.join(base_directory, 'val')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpOfpguNsSim"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "from keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "%matplotlib inline\n",
        "\n",
        "train_data_generator = ImageDataGenerator(\n",
        "                    rescale=1./255,\n",
        "                    rotation_range=20,\n",
        "                    horizontal_flip=True,\n",
        "                    shear_range = 0.2,\n",
        "                    fill_mode = 'nearest')\n",
        " \n",
        "test_data_generator = ImageDataGenerator(\n",
        "                    rescale=1./255,\n",
        "                    rotation_range=20,\n",
        "                    horizontal_flip=True,\n",
        "                    shear_range = 0.2,\n",
        "                    fill_mode = 'nearest')\n",
        "\n",
        "train_generator = train_data_generator.flow_from_directory(\n",
        "        train_directory,  \n",
        "        target_size=(150, 150),  \n",
        "        batch_size=16,\n",
        "        class_mode='categorical'\n",
        "        )\n",
        " \n",
        "validation_generator = test_data_generator.flow_from_directory(\n",
        "        val_directory,\n",
        "        target_size=(150, 150), \n",
        "        batch_size=16, \n",
        "        class_mode='categorical'\n",
        "        )\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "    tf.keras.layers.Conv2D(256, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=tf.optimizers.Adam(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "class CustomCallBack(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    if logs.get('accuracy') >= 0.97 :\n",
        "      print('Accuray model over 97%, stopping training model !')\n",
        "      self.model.stop_training = True\n",
        "\n",
        "history = model.fit(\n",
        "          train_generator,\n",
        "          steps_per_epoch=30,\n",
        "          epochs=20,\n",
        "          validation_data=validation_generator, \n",
        "          validation_steps=5,  \n",
        "          verbose=2,\n",
        "          callbacks = [CustomCallBack()]\n",
        "          )\n",
        "\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iboSKMKcGzv"
      },
      "source": [
        "uploaded = files.upload()\n",
        "for fn in uploaded.keys():\n",
        "  path = fn\n",
        "  img = image.load_img(path, target_size=(150,150))\n",
        "  imgplot = plt.imshow(img)\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "\n",
        "images = np.vstack([x])\n",
        "classes = model.predict(images, batch_size=10)\n",
        "\n",
        "if classes[0,0] != 0:\n",
        "  print('Picture = Paper')\n",
        "elif classes[0,1] != 0 :\n",
        "  print('Picture = Rock')\n",
        "else:\n",
        "  print('Picture = Scissors')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}